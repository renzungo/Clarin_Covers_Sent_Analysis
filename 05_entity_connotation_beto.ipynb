{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyPL1LByCz98xsNg/plT5IiS",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "be05a253f64a473898be5e1e70de6377": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53feb97bfe244a81859e2e0977c081ae",
       "IPY_MODEL_93f92e147f624c3c948926e842ef3834",
       "IPY_MODEL_7fad6ae0e3024bd6944a7f2570199306"
      ],
      "layout": "IPY_MODEL_0bd5f15169df4fffb3b591478c30dc47"
     }
    },
    "53feb97bfe244a81859e2e0977c081ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96e437f7d0254614bc1cb2843f0fee9f",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_fd996888dd5a483bbc7058f4edec00c9",
      "value": "Streaming\u2007entities\u2007per\u2007cover:\u2007100%"
     }
    },
    "93f92e147f624c3c948926e842ef3834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0676f7053ccc4ed49a87181cdb3e9c3b",
      "max": 652,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0326f359408a4391ba0a13e872abeacb",
      "value": 652
     }
    },
    "7fad6ae0e3024bd6944a7f2570199306": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c641738776f439996eea408394e00ee",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_5acc596605694b1e8f0dc24cf795fadd",
      "value": "\u2007652/652\u2007[38:41&lt;00:00,\u2007\u20073.09s/it]"
     }
    },
    "0bd5f15169df4fffb3b591478c30dc47": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96e437f7d0254614bc1cb2843f0fee9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd996888dd5a483bbc7058f4edec00c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0676f7053ccc4ed49a87181cdb3e9c3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0326f359408a4391ba0a13e872abeacb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0c641738776f439996eea408394e00ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5acc596605694b1e8f0dc24cf795fadd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/renzungo/Clarin_Covers_Sent_Analysis/blob/sentiment/05_entity_connotation_beto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z2Hl9jpO2UmA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "be05a253f64a473898be5e1e70de6377",
      "53feb97bfe244a81859e2e0977c081ae",
      "93f92e147f624c3c948926e842ef3834",
      "7fad6ae0e3024bd6944a7f2570199306",
      "0bd5f15169df4fffb3b591478c30dc47",
      "96e437f7d0254614bc1cb2843f0fee9f",
      "fd996888dd5a483bbc7058f4edec00c9",
      "0676f7053ccc4ed49a87181cdb3e9c3b",
      "0326f359408a4391ba0a13e872abeacb",
      "0c641738776f439996eea408394e00ee",
      "5acc596605694b1e8f0dc24cf795fadd"
     ]
    },
    "outputId": "01295856-8552-406e-fee9-9611b415122c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "Total covers with entities: 652 | Already done: 0 | To do: 652\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Streaming entities per cover:   0%|          | 0/652 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be05a253f64a473898be5e1e70de6377"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done streaming. Appended 652 file(s). Elapsed: 38.7 min\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive; drive.mount('/content/drive', force_remount=True)\n",
    "!pip -q install transformers==4.43.3 torch pandas unidecode tqdm\n",
    "\n",
    "import os, math, hashlib, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from unidecode import unidecode\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# ---------------- Paths ----------------\n",
    "WORK_DIR = \"/content/drive/MyDrive/Data Justicialista/Clarin Cover Sentiment Analysis/odc_pipeline_work\"\n",
    "OUT_DIR  = \"/content/drive/MyDrive/Data Justicialista/Clarin Cover Sentiment Analysis/odc_analytics_out\"\n",
    "CACHE    = \"/content/drive/MyDrive/hf_cache\"\n",
    "os.makedirs(WORK_DIR, exist_ok=True); os.makedirs(OUT_DIR, exist_ok=True); os.makedirs(CACHE, exist_ok=True)\n",
    "\n",
    "ENT_OUT = os.path.join(OUT_DIR, \"entities_sentiment.csv\")\n",
    "DONE_LOG = os.path.join(OUT_DIR, \"entities_done.txt\")   # keeps processed file names (one per line)\n",
    "\n",
    "# ---------------- Speed knobs (tuned) ----------------\n",
    "MODEL_ID = \"pysentimiento/robertuito-sentiment-analysis\"   # fast Spanish POS/NEU/NEG\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "KEEP_ENTITY_TYPES = {\"PER\"}        # people only (fastest). Add \"ORG\",\"LOC\",\"GPE\" if needed.\n",
    "CAP_WINDOWS_PER_ENTITY = 2         # at most N windows per (file, entity, type)\n",
    "DEDUP_WINDOWS = True               # deduplicate identical windows within file\n",
    "CHAR_RADIUS = 100                  # \u00b1100 chars around mention\n",
    "MAX_LEN_TOKENS = 128\n",
    "BATCH = 256\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# ---------------- Load inputs ----------------\n",
    "df_base  = pd.read_parquet(os.path.join(WORK_DIR, \"base.parquet\"))       # file,date,text\n",
    "df_spans = pd.read_parquet(os.path.join(WORK_DIR, \"ner_spans.parquet\"))  # file,date,entity_text,entity_type,start,end\n",
    "print(f\"[DEBUG] df_base shape: {df_base.shape} | df_spans shape: {df_spans.shape}\")  # Debug: input sizes\n",
    "if KEEP_ENTITY_TYPES:\n",
    "    df_spans = df_spans[df_spans[\"entity_type\"].isin(KEEP_ENTITY_TYPES)]\n",
    "\n",
    "text_map = {r.file: (r.text or \"\") for r in df_base.itertuples(index=False)}\n",
    "\n",
    "# Files to process (those that have any span)\n",
    "files_with_spans = df_spans[\"file\"].drop_duplicates().tolist()\n",
    "\n",
    "# Progress log helpers\n",
    "# Read log of already processed files\n",
    "def load_done(log_path):\n",
    "    if not os.path.exists(log_path): return set()\n",
    "    with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return set([ln.strip() for ln in f if ln.strip()])\n",
    "# Append a filename to the processed log\n",
    "def append_done(log_path, fname):\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(fname + \"\\n\")\n",
    "\n",
    "done = load_done(DONE_LOG)\n",
    "todo = [f for f in files_with_spans if f not in done]\n",
    "print(f\"Total covers with entities: {len(files_with_spans)} | Already done: {len(done)} | To do: {len(todo)}\")\n",
    "\n",
    "# Ensure output file exists with header\n",
    "if not os.path.exists(ENT_OUT):\n",
    "    pd.DataFrame(columns=[\"file\",\"date\",\"entity_norm\",\"entity_type\",\"mentions\",\"avg_score\",\"pos_share\",\"neu_share\",\"neg_share\"])\\\n",
    "      .to_csv(ENT_OUT, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# ---------------- Load model (direct, no pipeline) ----------------\n",
    "load_kwargs = {\"cache_dir\": CACHE}\n",
    "if DEVICE == \"cuda\":\n",
    "    load_kwargs[\"torch_dtype\"] = torch.float16\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, cache_dir=CACHE, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID, **load_kwargs).to(DEVICE).eval()\n",
    "id2label = model.config.id2label\n",
    "\n",
    "# Efficient batched sentiment prediction without gradient tracking\n",
    "@torch.no_grad()\n",
    "def predict(texts):\n",
    "    out_labels, out_scores = [], []\n",
    "    for i in range(0, len(texts), BATCH):\n",
    "        batch = texts[i:i+BATCH]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=MAX_LEN_TOKENS, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(DEVICE, non_blocking=True) for k,v in enc.items()}\n",
    "        with torch.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
    "            logits = model(**enc).logits\n",
    "    # Convert similarities to pseudo-probabilities\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        best_idx = torch.argmax(probs, dim=-1)\n",
    "        best_prob = probs.gather(1, best_idx.unsqueeze(1)).squeeze(1)\n",
    "        out_labels.extend([id2label[int(i)] for i in best_idx.tolist()])\n",
    "        out_scores.extend(best_prob.tolist())\n",
    "    return out_labels, out_scores\n",
    "\n",
    "# Build sentiment windows around entities for a single cover\n",
    "def process_one_file(fname: str, debug=False):\n",
    "    # Spans for this file\n",
    "    s = df_spans[df_spans[\"file\"] == fname].copy()\n",
    "    if s.empty:\n",
    "        return None\n",
    "    date = s[\"date\"].iloc[0]\n",
    "    text = text_map.get(fname, \"\")\n",
    "    # Build windows for this file\n",
    "    rows = []\n",
    "    for r in s.itertuples(index=False):\n",
    "        lo = max(0, int(r.start) - CHAR_RADIUS); hi = min(len(text), int(r.end) + CHAR_RADIUS)\n",
    "        win = text[lo:hi].strip()\n",
    "        if not win:\n",
    "            continue\n",
    "        rows.append({\"file\": fname,\n",
    "                     \"date\": date,\n",
    "                     \"entity_norm\": unidecode(r.entity_text).lower().strip(),\n",
    "                     \"entity_type\": r.entity_type,\n",
    "                     \"window\": win})\n",
    "    if not rows:\n",
    "        return None\n",
    "    df = pd.DataFrame(rows)\n",
    "    if debug:\n        print(f\"[DEBUG] {fname} windows sample: {df.head()}\")  # Debug: show sample windows\n",
    "\n",
    "    # Cap windows per entity for this file\n",
    "    if CAP_WINDOWS_PER_ENTITY is not None:\n",
    "        df = (df.groupby([\"entity_norm\",\"entity_type\"], as_index=False, sort=False)\n",
    "                .head(CAP_WINDOWS_PER_ENTITY))\n",
    "\n",
    "    # Dedup windows within this file\n",
    "    if DEDUP_WINDOWS:\n",
    "        df[\"win_hash\"] = df[\"window\"].map(lambda t: hashlib.sha1(t.encode(\"utf-8\")).hexdigest())\n",
    "        uniq = df.drop_duplicates(\"win_hash\", keep=\"first\")[[\"win_hash\",\"window\"]].reset_index(drop=True)\n",
    "    else:\n",
    "        df[\"win_hash\"] = pd.util.hash_pandas_object(df[\"window\"], index=False).astype(str)\n",
    "        uniq = df[[\"win_hash\",\"window\"]].copy()\n",
    "\n",
    "    # Predict once per unique window\n",
    "    lbls, scs = predict(uniq[\"window\"].tolist())\n",
    "    uniq[\"label\"], uniq[\"score\"] = lbls, scs\n",
    "    pred_map = dict(zip(uniq[\"win_hash\"], zip(uniq[\"label\"], uniq[\"score\"])))\n",
    "\n",
    "    # Fan back to all windows\n",
    "    df[\"label\"] = df[\"win_hash\"].map(lambda h: pred_map[h][0])\n",
    "    df[\"score\"] = df[\"win_hash\"].map(lambda h: pred_map[h][1])\n",
    "\n",
    "    # Aggregate to (file, date, entity_norm, entity_type)\n",
    "    def share(series, target):\n",
    "        if len(series) == 0: return 0.0\n",
    "        return float(np.mean([1.0 if x == target else 0.0 for x in series]))\n",
    "\n",
    "    # Aggregate window scores per entity\n",
    "    agg = (df.groupby([\"file\",\"date\",\"entity_norm\",\"entity_type\"], as_index=False)\n",
    "             .agg(mentions=(\"label\",\"count\"),\n",
    "                  avg_score=(\"score\",\"mean\"),\n",
    "                  pos_share=(\"label\", lambda s: share(s, \"POS\")),\n",
    "                  neu_share=(\"label\", lambda s: share(s, \"NEU\")),\n",
    "                  neg_share=(\"label\", lambda s: share(s, \"NEG\"))))\n",
    "    if debug:\n        print(f\"[DEBUG] Aggregated sentiment: {agg.head()}\")  # Debug: sample aggregated\n",
    "    return agg\n",
    "\n",
    "# ---------------- Stream: process file-by-file and append ----------------\n",
    "start = time.time()\n",
    "# Stream through remaining files and append results\n",
    "for idx, fname in enumerate(tqdm(todo, desc=\"Streaming entities per cover\")):\n",
    "    agg = process_one_file(fname, debug=(idx==0))\n",
    "    if idx == 0:\n        print(f\"[DEBUG] First file processed: {fname}\")  # Debug: shows file name\n",
    "    if agg is not None and not agg.empty:\n",
    "        # Append to CSV without header\n",
    "        # Append aggregated sentiment to CSV output\n",
    "        agg.to_csv(ENT_OUT, mode=\"a\", index=False, header=False, encoding=\"utf-8\")\n",
    "    append_done(DONE_LOG, fname)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Done streaming. Appended {len(todo)} file(s). Elapsed: {elapsed/60:.1f} min\")\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  }
 ]
}