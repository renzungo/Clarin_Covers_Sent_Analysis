{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renzungo/Clarin_Covers_Sent_Analysis/blob/sentiment/03_overall_sentiment_beto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 692,
          "referenced_widgets": [
            "56f4b4e9a0b84926a267f9165e89bd2b"
          ]
        },
        "id": "8f9Pq6Tl0Xu5",
        "outputId": "634ed754-6adc-4925-b745-51f340c1ab79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56f4b4e9a0b84926a267f9165e89bd2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/652 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /content/drive/MyDrive/Data Justicialista/Clarin Cover Sentiment Analysis/odc_pipeline_work/sentiment.parquet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive; drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!pip -q install transformers==4.43.3 torch pandas unidecode tqdm\n",
        "\n",
        "import os, re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from unidecode import unidecode\n",
        "from transformers import pipeline\n",
        "\n",
        "WORK_DIR = \"/content/drive/MyDrive/Data Justicialista/Clarin Cover Sentiment Analysis/odc_pipeline_work\"\n",
        "OUT_DIR = \"/content/drive/MyDrive/Data Justicialista/Clarin Cover Sentiment Analysis/odc_analytics_out\"\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "SENT_CLF = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"finiteautomata/beto-sentiment-analysis\",\n",
        "    tokenizer=\"finiteautomata/beto-sentiment-analysis\",\n",
        "    top_k=None\n",
        ")\n",
        "\n",
        "ECONOMY_KWS = {\n",
        "    \"inflación\",\"inflacion\",\"dólar\",\"dolar\",\"salario\",\"precios\",\"devaluación\",\"devaluacion\",\n",
        "    \"pbi\",\"actividad\",\"desempleo\",\"impuestos\",\"tarifas\",\"deuda\",\"fmi\",\"paritarias\",\"exportaciones\",\"importaciones\"\n",
        "}\n",
        "GOVERNMENT_KWS = {\n",
        "    \"presidente\",\"presidenta\",\"gobierno\",\"ministro\",\"ministra\",\"gabinete\",\"decreto\",\n",
        "    \"congreso\",\"senado\",\"diputados\",\"casa rosada\",\"boletín oficial\",\"boletin oficial\"\n",
        "}\n",
        "ECO = {unidecode(k).lower() for k in ECONOMY_KWS}\n",
        "GOV = {unidecode(k).lower() for k in GOVERNMENT_KWS}\n",
        "\n",
        "def tokenize_simple(text: str):\n",
        "    t = unidecode(text).lower()\n",
        "    return re.findall(r\"[a-záéíóúñ]+\", t)\n",
        "\n",
        "def window_sentiment(text_tokens, hits, radius=30):\n",
        "    if not hits: return None, None\n",
        "    lo_hi = [(max(0,i-radius), min(len(text_tokens), i+radius+1)) for i in hits]\n",
        "    joined = \" \".join(\" \".join(text_tokens[lo:hi]) for lo,hi in lo_hi)[:900]\n",
        "    pred = SENT_CLF(joined)[0][0]  # Access the dictionary within the nested lists\n",
        "    return pred[\"label\"], float(pred[\"score\"])\n",
        "\n",
        "df_base = pd.read_parquet(os.path.join(WORK_DIR, \"base.parquet\"))\n",
        "\n",
        "rows = []\n",
        "for r in tqdm(df_base.itertuples(index=False), total=len(df_base)):\n",
        "    text = r.text or \"\"\n",
        "    if not text:\n",
        "        rows.append({\"file\": r.file, \"date\": r.date,\n",
        "                     \"overall_sentiment\":\"VACIO\",\"overall_score\":0.0,\n",
        "                     \"eco_share\":0.0,\"eco_sentiment\":None,\"eco_sent_score\":None,\n",
        "                     \"gov_share\":0.0,\"gov_sentiment\":None,\"gov_sent_score\":None})\n",
        "        continue\n",
        "\n",
        "    pred = SENT_CLF(text[:1000])[0][0] # Access the dictionary within the nested lists\n",
        "    tokens = tokenize_simple(text)\n",
        "    hits_eco = [i for i,t in enumerate(tokens) if t in ECO]\n",
        "    hits_gov = [i for i,t in enumerate(tokens) if t in GOV]\n",
        "    eco_share = 0.0 if not tokens else len(hits_eco)/len(tokens)\n",
        "    gov_share = 0.0 if not tokens else len(hits_gov)/len(tokens)\n",
        "\n",
        "    eco_lbl, eco_sc = window_sentiment(tokens, hits_eco)\n",
        "    gov_lbl, gov_sc = window_sentiment(tokens, hits_gov)\n",
        "\n",
        "    rows.append({\"file\": r.file, \"date\": r.date,\n",
        "                 \"overall_sentiment\": pred[\"label\"], \"overall_score\": float(pred[\"score\"]),\n",
        "                 \"eco_share\": eco_share, \"eco_sentiment\": eco_lbl, \"eco_sent_score\": eco_sc,\n",
        "                 \"gov_share\": gov_share, \"gov_sentiment\": gov_lbl, \"gov_sent_score\": gov_sc})\n",
        "\n",
        "df_sent = pd.DataFrame(rows)\n",
        "df_sent.to_parquet(os.path.join(WORK_DIR, \"sentiment.parquet\"), index=False)\n",
        "print(\"Wrote:\", os.path.join(WORK_DIR, \"sentiment.parquet\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMiOaCEXRL5KPnHA0ohm9od",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}